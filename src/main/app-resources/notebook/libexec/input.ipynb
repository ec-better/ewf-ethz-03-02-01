{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ETHZ-03-02-01 Map of b0 changes - Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data processor developer, I want to implement, and package an algorithm processing a pair of S1 SAR SLC datasets using the SNAP toolbox notebook archetype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quick link\n",
    "\n",
    "* [Objective](#objective)\n",
    "* [Test Site](#test-site)\n",
    "* [Context](#context)\n",
    "* [Applicability](#applicability)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [Strengths and Limitations](#strengths-limitations) \n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"objective\">Objective \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"data\">Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "SENTINEL data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. Radar data will be delivered within an hour of reception for Near Real-Time (NRT) emergency response, within three hours for NRT priority areas and within 24 hours for systematically archived data.\n",
    "\n",
    "All data products are distributed in the SENTINEL Standard Archive Format for Europe (SAFE) format.\n",
    "\n",
    "Data products are available in single polarisation (VV or HH) for Wave mode and dual polarisation (VV+VH or HH+HV) and single polarisation (HH or VV) for SM, IW and EW modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ETHZ-03-02-01 Map of b0 changes'),\n",
    "                ('abstract', 'This application takes a pair of Sentinel-1 products and generates a map of b0 changes'),\n",
    "                ('id', 'ewf-ethz-03-02-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output file format:\n",
    "\n",
    "* BEAM-DIMAP\n",
    "* GeoTIFF-BigTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = dict([('id', 'format'),\n",
    "               ('value', 'GeoTIFF-BigTIFF'),\n",
    "               ('title', 'Output file format'),\n",
    "               ('abstract', 'Output file format: BEAM-DIMAP or GeoTIFF-BigTIFF')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition\n",
    "    \n",
    "The variable values in this section are only relevant for the basic test case. In an actual processing context, the values are replaced by those of the parameters for the process execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of master and slave products' identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_identifiers = ('S1A_IW_SLC__1SDV_20161030T163141_20161030T163208_013722_01603F_4094', 'S1A_IW_SLC__1SDV_20161018T163141_20161018T163208_013547_015AEB_5994')\n",
    "\n",
    "input_identifiers = ('S1A_IW_SLC__1SDV_20161107T170553_20161107T170620_013839_0163F7_A66D', 'S1A_IW_SLC__1SDV_20161026T170553_20161026T170620_013664_015E7F_BD83')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack of catalogue references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input_references = ('https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161030T163141_20161030T163208_013722_01603F_4094', 'https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161018T163141_20161018T163208_013547_015AEB_5994')\n",
    "\n",
    "input_references = ('https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161107T170553_20161107T170620_013839_0163F7_A66D','https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161026T170553_20161026T170620_013664_015E7F_BD83')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/Better_3rd_phase/Applications/ETHZ-03-02-01/temp/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "\n",
    "import dateutil.parser as parser\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import gdal\n",
    "import osr\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import box\n",
    "\n",
    "import lxml.etree as etree\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as etree\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "import psutil\n",
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "import os\n",
    "\n",
    "class GraphProcessor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.root = etree.Element('graph')\n",
    "    \n",
    "        version = etree.SubElement(self.root, 'version')\n",
    "        version.text = '1.0'\n",
    "        self.pid = None\n",
    "        self.p = None\n",
    "   \n",
    "    def view_graph(self):\n",
    "        \n",
    "        print etree.tostring(self.root , pretty_print=True)\n",
    "        \n",
    "    def add_node(self, node_id, operator, parameters, source):\n",
    "    \n",
    "        xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "\n",
    "        if len(self.root.xpath(xpath_expr)) != 0:\n",
    "\n",
    "            node_elem = self.root.xpath(xpath_expr)[0]\n",
    "            operator_elem = self.root.xpath(xpath_expr + '/operator')[0]\n",
    "            sources_elem = self.root.xpath(xpath_expr + '/sources')[0]\n",
    "            parameters_elem = self.root.xpath(xpath_expr + '/parameters')\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "                p_elem = self.root.xpath(xpath_expr + '/parameters/%s' % key)[0]\n",
    "                p_elem.text = value\n",
    "        else:\n",
    "\n",
    "            node_elem = etree.SubElement(self.root, 'node')\n",
    "            operator_elem = etree.SubElement(node_elem, 'operator')\n",
    "            sources_elem = etree.SubElement(node_elem, 'sources')\n",
    "\n",
    "            if isinstance(source, list):\n",
    "\n",
    "                for index, s in enumerate(source):\n",
    "                    if index == 0:  \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "\n",
    "                    else: \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct.%s' % str(index))\n",
    "\n",
    "                    source_product_elem.attrib['refid'] = s\n",
    "\n",
    "            elif source != '':\n",
    "                source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "                source_product_elem.attrib['refid'] = source\n",
    "\n",
    "            parameters_elem = etree.SubElement(node_elem, 'parameters')\n",
    "            parameters_elem.attrib['class'] = 'com.bc.ceres.binding.dom.XppDomElement'\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "\n",
    "                parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                parameter_elem.text = value\n",
    "\n",
    "        node_elem.attrib['id'] = node_id\n",
    "\n",
    "        operator_elem.text = operator \n",
    "\n",
    "    def save_graph(self, filename):\n",
    "        \n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "            file.write(etree.tostring(self.root, pretty_print=True))\n",
    "     \n",
    "    def plot_graph(self):\n",
    "        \n",
    "        for node_id in self.root.xpath('/graph/node/@id'):\n",
    "            \n",
    "\n",
    "            xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "            \n",
    "            if len(self.root.xpath(xpath_expr + '/sources/sourceProduct')) != 0:\n",
    "                print(self.root.xpath(xpath_expr + '/sources/sourceProduct'))[0].attrib['refid']\n",
    "                print node_id\n",
    "            else:\n",
    "                print node_id\n",
    "        return True\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        fd, path = tempfile.mkstemp()\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            #options = ['/opt/snap6/bin/gpt',\n",
    "            #   '-x',\n",
    "            #   '-c',\n",
    "            #   '2048M',\n",
    "            #   path]\n",
    "            \n",
    "            options = ['/workspace/temp/temp/snap6/snap6/bin/gpt',\n",
    "               '-x',\n",
    "               '-c',\n",
    "               '2048M',\n",
    "               path]\n",
    "\n",
    "            p = subprocess.Popen(options,\n",
    "                stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "            print p.pid\n",
    "            res, err = p.communicate()\n",
    "            print res, err\n",
    "            if p.returncode != 0:\n",
    "                raise Exception('An error occurred during the execution of gpt (see log)')\n",
    "            \n",
    "        except Exception as e:\n",
    "            with open('stdout.txt', 'wb') as file:\n",
    "                file.write(res)\n",
    "                file.close()\n",
    "            with open('stderr.txt', 'wb') as file:\n",
    "                file.write(err)\n",
    "                file.close()\n",
    "            \n",
    "            raise\n",
    "        finally:\n",
    "            os.remove(path)\n",
    "        \n",
    "def get_snap_parameters(operator):\n",
    "    \n",
    "    op_spi = GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpi(operator)\n",
    "\n",
    "    op_params = op_spi.getOperatorDescriptor().getParameterDescriptors()\n",
    "\n",
    "    return op_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "read_nodes = []\n",
    "\n",
    "for index, identifier in enumerate(input_identifiers):\n",
    "    \n",
    "    parameters = dict()\n",
    "\n",
    "    for param in get_snap_parameters(operator):\n",
    "    \n",
    "        if param.getName() == 'file':\n",
    "            parameters[param.getName()] = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')    \n",
    "        else:\n",
    "            parameters[param.getName()] = param.getDefaultValue()\n",
    "    node_id = 'Read(%s)' % index\n",
    "    \n",
    "    read_nodes.append(node_id)\n",
    "    \n",
    "    mygraph.add_node(node_id, 'Read', parameters, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_nodes = []\n",
    "\n",
    "for index, source_node in enumerate(read_nodes):\n",
    "    \n",
    "    node_id = 'Apply-Orbit-File(%s)' % index\n",
    "    \n",
    "    orbit_nodes.append(node_id)\n",
    "    \n",
    "    mygraph.add_node(node_id, 'Apply-Orbit-File', parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPSAR split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Split'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_split_nodes = []\n",
    "master_split_nodes = []\n",
    "\n",
    "for index_node, source_node in enumerate(orbit_nodes):\n",
    "    \n",
    "    for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "    \n",
    "        parameters['subswath'] =  subswath\n",
    "        parameters['selectedPolarisations'] = 'VV'\n",
    "\n",
    "        node_id = 'TOPSAR-Split(%s)' % str(index_node * 3 + index)\n",
    "    \n",
    "        if index_node == 0:\n",
    "            slave_split_nodes.append(node_id)\n",
    "        else:\n",
    "            master_split_nodes.append(node_id)\n",
    "    \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Back-Geocoding'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgeo_nodes = []\n",
    "    \n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "            \n",
    "    node_id = 'Back-Geocoding(%s)' % index\n",
    "   \n",
    "    source_nodes = [slave_split_nodes[index], master_split_nodes[index]]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "    backgeo_nodes.append(node_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interferogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Interferogram'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interferogram_nodes = []\n",
    "\n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "            \n",
    "    node_id = 'Interferogram(%s)' % index\n",
    "   \n",
    "    source_node = backgeo_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "\n",
    "    interferogram_nodes.append(node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOPSAR Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Deburst'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deburst_nodes = []\n",
    "\n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    " \n",
    "    parameters['selectedPolarisations'], 'VV'\n",
    "\n",
    "    node_id = 'TOPSAR-Deburst(%s)' % index\n",
    "   \n",
    "    source_node = interferogram_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "\n",
    "    deburst_nodes.append(node_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOPSAR Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Merge'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['selectedPolarisations'], 'VV'\n",
    "\n",
    "source_nodes = deburst_nodes\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TopoPhaseRemoval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TopoPhaseRemoval'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_node = 'TOPSAR-Merge'\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GoldsteinPhaseFiltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'GoldsteinPhaseFiltering'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_node = 'TopoPhaseRemoval'\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Terrain-Correction'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_node = 'GoldsteinPhaseFiltering'\n",
    "\n",
    "parameters['outputComplex'] = 'true'\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciop = cioppy.Cioppy()\n",
    "\n",
    "search = ciop.search(end_point=input_references[0],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP') \n",
    "\n",
    "search2 = ciop.search(end_point=input_references[1],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP')\n",
    "\n",
    "if (search[0]['startdate'] < search2[0]['startdate']):\n",
    "    start_date = search[0]['startdate']\n",
    "else:\n",
    "    start_date = search2[0]['startdate']\n",
    "\n",
    "if (search[0]['enddate'] > search2[0]['enddate']):\n",
    "    end_date = search[0]['enddate']\n",
    "else:\n",
    "    end_date = search2[0]['enddate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'S1_IFG_%s_%s_%s' % (\"%03d\"%int(search[0]['wrsLongitudeGrid']), \n",
    "                                    parser.parse(start_date).strftime('%Y%m%d_%H%M%S'),\n",
    "                                    parser.parse(end_date).strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    " \n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        \n",
    "        param_value = output_name\n",
    "             \n",
    "    elif param.getName() == 'formatName':\n",
    "                \n",
    "        param_value = 'BEAM-DIMAP'\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        param_value = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    print param.getName(), param_value\n",
    "    \n",
    "    parameters[param.getName()] = param_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(operator, \n",
    "             operator, \n",
    "             parameters,\n",
    "             'Terrain-Correction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ProductIO.getProductReader(\"BEAM-DIMAP\")\n",
    "\n",
    "ifg = reader.readProductNodes(output_name + '.dim', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = ifg.getBandNames()\n",
    "target_bands = list(band_names) \n",
    "target_bands.append(target_bands[0].replace('i_', 'phase_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "\n",
    "targetBands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', len(target_bands))\n",
    "\n",
    "for index, band in enumerate(target_bands):\n",
    "     \n",
    "    targetBand = BandDescriptor()\n",
    "    \n",
    "    if 'phase_' in band:\n",
    "       \n",
    "        targetBand.expression = 'atan2(%s, %s)' % (target_bands[1], target_bands[0])\n",
    "   \n",
    "    else:\n",
    "    \n",
    "        targetBand.expression = band\n",
    "\n",
    "    targetBand.name = band\n",
    "    targetBand.type = 'float32'\n",
    "    \n",
    "    targetBands[index]= targetBand\n",
    "        \n",
    "\n",
    "parameters = HashMap()\n",
    "parameters.put('targetBands', targetBands)\n",
    "\n",
    "result = GPF.createProduct('BandMaths', parameters, ifg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductIO.writeProduct(result, \n",
    "                       output_name + '.tif',\n",
    "                       'GeoTIFF-BigTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eop_metadata(metadata):\n",
    "\n",
    "    opt = 'http://www.opengis.net/opt/2.1'\n",
    "    om  = 'http://www.opengis.net/om/2.0'\n",
    "    gml = 'http://www.opengis.net/gml/3.2'\n",
    "    eop = 'http://www.opengis.net/eop/2.1'\n",
    "    sar = 'http://www.opengis.net/sar/2.1'\n",
    "    \n",
    "    root = etree.Element('{%s}EarthObservation' % sar)\n",
    "\n",
    "    phenomenon_time = etree.SubElement(root, '{%s}phenomenonTime' % om)\n",
    "\n",
    "    time_period = etree.SubElement(phenomenon_time, '{%s}TimePeriod' % gml)\n",
    "\n",
    "    begin_position = etree.SubElement(time_period, '{%s}beginPosition'  % gml)\n",
    "\n",
    "    end_position = etree.SubElement(time_period, '{%s}endPosition'  % gml)\n",
    "\n",
    "    procedure = etree.SubElement(root, '{%s}procedure' % om)\n",
    "\n",
    "    earth_observation_equipment = etree.SubElement(procedure, '{%s}EarthObservationEquipment' % eop)\n",
    "\n",
    "    acquisition_parameters = etree.SubElement(earth_observation_equipment, '{%s}acquisitionParameters' % eop)\n",
    "\n",
    "    acquisition = etree.SubElement(acquisition_parameters, '{%s}Acquisition' % sar)\n",
    "\n",
    "    orbit_number = etree.SubElement(acquisition, '{%s}orbitNumber' % eop)\n",
    "\n",
    "    wrs_longitude_grid = etree.SubElement(acquisition, '{%s}wrsLongitudeGrid' % eop)\n",
    "\n",
    "    polarisation_channels = etree.SubElement(acquisition, '{%s}polarisationChannels' % eop)\n",
    "    \n",
    "    feature_of_interest = etree.SubElement(root, '{%s}featureOfInterest' % om)\n",
    "    footprint = etree.SubElement(feature_of_interest, '{%s}Footprint' % eop)\n",
    "    multi_extentOf = etree.SubElement(footprint, '{%s}multiExtentOf' % eop)\n",
    "    multi_surface = etree.SubElement(multi_extentOf, '{%s}MultiSurface' % gml)\n",
    "    surface_members = etree.SubElement(multi_surface, '{%s}surfaceMembers' % gml)\n",
    "    polygon = etree.SubElement(surface_members, '{%s}Polygon' % gml)    \n",
    "    exterior = etree.SubElement(polygon, '{%s}exterior' % gml)  \n",
    "    linear_ring = etree.SubElement(exterior, '{%s}LinearRing' % gml) \n",
    "    poslist = etree.SubElement(linear_ring, '{%s}posList' % gml) \n",
    "\n",
    "\n",
    "    result = etree.SubElement(root, '{%s}result' % om)\n",
    "    earth_observation_result = etree.SubElement(result, '{%s}EarthObservationResult' % opt)\n",
    "    cloud_cover_percentage = etree.SubElement(earth_observation_result, '{%s}cloudCoverPercentage' % opt)\n",
    "    \n",
    "    metadata_property = etree.SubElement(root, '{%s}metaDataProperty' % eop)\n",
    "    earth_observation_metadata = etree.SubElement(metadata_property, '{%s}EarthObservationMetaData' % eop)\n",
    "    identifier = etree.SubElement(earth_observation_metadata, '{%s}identifier' % eop)\n",
    "    \n",
    "    begin_position.text = metadata['startdate']\n",
    "    end_position.text = metadata['enddate']\n",
    "    #orbit_number.text = metadata['orbitNumber']\n",
    "    wrs_longitude_grid.text = metadata['wrsLongitudeGrid']\n",
    "    \n",
    "    coords = np.asarray([t[::-1] for t in list(loads(metadata['wkt']).exterior.coords)]).tolist()\n",
    " \n",
    "    pos_list = ''\n",
    "    for elem in coords:\n",
    "        pos_list += ' '.join(str(e) for e in elem) + ' '   \n",
    "\n",
    "    poslist.attrib['count'] = str(len(coords))\n",
    "    poslist.text = pos_list\n",
    "    \n",
    "    \n",
    "    identifier.text = metadata['identifier'] \n",
    "\n",
    "    return etree.tostring(root, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(output_name + '.tif')\n",
    "ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "\n",
    "max_x = ulx + (src.RasterXSize * xres)\n",
    "min_y = uly + (src.RasterYSize * yres)\n",
    "min_x = ulx \n",
    "max_y = uly\n",
    "\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromWkt(src.GetProjection())\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(4326)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "result_wkt = box(transform.TransformPoint(min_x, min_y)[0],\n",
    "        transform.TransformPoint(min_x, min_y)[1],\n",
    "        transform.TransformPoint(max_x, max_y)[0],\n",
    "        transform.TransformPoint(max_x, max_y)[1]).wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search[0]['identifier'] = output_name\n",
    "search[0]['wkt'] = result_wkt\n",
    "\n",
    "search[0]['startdate'] = start_date\n",
    "search[0]['enddate'] = end_date\n",
    "\n",
    "eop_xml = output_name + '.xml'\n",
    "with open(eop_xml, 'wb') as file:\n",
    "    file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    file.write(eop_metadata(search[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for properties_file in ['result', 'stage-in']:\n",
    "\n",
    "    if properties_file == 'result':\n",
    "        title = 'Reproducibility notebook used for generating %s' % output_name\n",
    "    else: \n",
    "        title = 'Reproducibility stage-in notebook for Sentinel-1 data for generating %s' % output_name\n",
    "        \n",
    "    with open(properties_file + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (start_date, end_date))\n",
    "        file.write('geometry=%s' % (search[0]['wkt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(output_name + '.data')\n",
    "os.remove(output_name + '.dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
