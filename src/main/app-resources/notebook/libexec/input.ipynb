{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ETHZ-03-02-01 Map of b0 changes - Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm to detect SAR amplitude changes (b0) related to landslide events from pre- and post-earthquake Sentinel-1 IW-SLC acquisitions (slave, master)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quick link\n",
    "\n",
    "* [Objective](#objective)\n",
    "* [Test Site](#test-site)\n",
    "* [Context](#context)\n",
    "* [Applicability](#applicability)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [Strengths and Limitations](#strengths-limitations) \n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"objective\">Objective \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"data\">Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "SENTINEL data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. Radar data will be delivered within an hour of reception for Near Real-Time (NRT) emergency response, within three hours for NRT priority areas and within 24 hours for systematically archived data.\n",
    "\n",
    "All data products are distributed in the SENTINEL Standard Archive Format for Europe (SAFE) format.\n",
    "\n",
    "Data products are available in single polarisation (VV or HH) for Wave mode and dual polarisation (VV+VH or HH+HV) and single polarisation (HH or VV) for SM, IW and EW modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ETHZ-03-02-01 Map of b0 changes'),\n",
    "                ('abstract', 'This application takes a pair of Sentinel-1 products and generates a map of b0 changes'),\n",
    "                ('id', 'ewf-ethz-03-02-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output file format:\n",
    "\n",
    "* BEAM-DIMAP\n",
    "* GeoTIFF-BigTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = dict([('id', 'format'),\n",
    "               ('value', 'GeoTIFF-BigTIFF'),\n",
    "               ('title', 'Output file format'),\n",
    "               ('abstract', 'Output file format: BEAM-DIMAP or GeoTIFF-BigTIFF')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition\n",
    "    \n",
    "The variable values in this section are only relevant for the basic test case. In an actual processing context, the values are replaced by those of the parameters for the process execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of master and slave products' identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('S1A_IW_SLC__1SDV_20161107T170553_20161107T170620_013839_0163F7_A66D', 'S1A_IW_SLC__1SDV_20161026T170553_20161026T170620_013664_015E7F_BD83')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack of catalogue references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161107T170553_20161107T170620_013839_0163F7_A66D','https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161026T170553_20161026T170620_013664_015E7F_BD83')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/Better_3rd_phase/Applications/ETHZ-03-02-01/temp/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "\n",
    "import dateutil.parser as parser\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import gdal\n",
    "import osr\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import box\n",
    "\n",
    "import lxml.etree as etree\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as etree\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "import psutil\n",
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "import os\n",
    "\n",
    "class GraphProcessor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.root = etree.Element('graph')\n",
    "    \n",
    "        version = etree.SubElement(self.root, 'version')\n",
    "        version.text = '1.0'\n",
    "        self.pid = None\n",
    "        self.p = None\n",
    "   \n",
    "    def view_graph(self):\n",
    "        \n",
    "        print etree.tostring(self.root , pretty_print=True)\n",
    "        \n",
    "    def add_node(self, node_id, operator, parameters, source):\n",
    "    \n",
    "        xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "\n",
    "        if len(self.root.xpath(xpath_expr)) != 0:\n",
    "\n",
    "            node_elem = self.root.xpath(xpath_expr)[0]\n",
    "            operator_elem = self.root.xpath(xpath_expr + '/operator')[0]\n",
    "            sources_elem = self.root.xpath(xpath_expr + '/sources')[0]\n",
    "            parameters_elem = self.root.xpath(xpath_expr + '/parameters')\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "                p_elem = self.root.xpath(xpath_expr + '/parameters/%s' % key)[0]\n",
    "                p_elem.text = value\n",
    "        else:\n",
    "\n",
    "            node_elem = etree.SubElement(self.root, 'node')\n",
    "            operator_elem = etree.SubElement(node_elem, 'operator')\n",
    "            sources_elem = etree.SubElement(node_elem, 'sources')\n",
    "\n",
    "            if isinstance(source, list):\n",
    "\n",
    "                for index, s in enumerate(source):\n",
    "                    if index == 0:  \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "\n",
    "                    else: \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct.%s' % str(index))\n",
    "\n",
    "                    source_product_elem.attrib['refid'] = s\n",
    "\n",
    "            elif source != '':\n",
    "                source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "                source_product_elem.attrib['refid'] = source\n",
    "\n",
    "            parameters_elem = etree.SubElement(node_elem, 'parameters')\n",
    "            parameters_elem.attrib['class'] = 'com.bc.ceres.binding.dom.XppDomElement'\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "\n",
    "                # here I have to adapt the code\n",
    "                \n",
    "                if operator == 'BandMaths':\n",
    "                    \n",
    "                    if isinstance(value, dict):\n",
    "                        \n",
    "                        parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                        \n",
    "                        for key2, value2 in value.iteritems():\n",
    "                            parameter_elem2 = etree.SubElement(parameter_elem, key2)\n",
    "                            #parameter_elem.text = value\n",
    "                            if isinstance(value2, dict):\n",
    "                                for key3, value3 in value2.iteritems():\n",
    "                                    parameter_elem3 = etree.SubElement(parameter_elem2, key3)\n",
    "                                    parameter_elem3.text = value3\n",
    "                            pass\n",
    "                    \n",
    "                    else:\n",
    "                        parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                        parameter_elem.text = value\n",
    "                else:\n",
    "                    parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                    parameter_elem.text = value\n",
    "                    \n",
    "                    \n",
    "        \n",
    "        node_elem.attrib['id'] = node_id\n",
    "\n",
    "        operator_elem.text = operator \n",
    "\n",
    "    def save_graph(self, filename):\n",
    "        \n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "            file.write(etree.tostring(self.root, pretty_print=True))\n",
    "     \n",
    "    def plot_graph(self):\n",
    "        \n",
    "        for node_id in self.root.xpath('/graph/node/@id'):\n",
    "            \n",
    "\n",
    "            xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "            \n",
    "            if len(self.root.xpath(xpath_expr + '/sources/sourceProduct')) != 0:\n",
    "                print(self.root.xpath(xpath_expr + '/sources/sourceProduct'))[0].attrib['refid']\n",
    "                print node_id\n",
    "            else:\n",
    "                print node_id\n",
    "        return True\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        fd, path = tempfile.mkstemp()\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            self.save_graph(filename=path)\n",
    "            \n",
    "            options = ['/opt/snap6/bin/gpt',\n",
    "               '-x',\n",
    "               '-c',\n",
    "               '2048M',\n",
    "               path]\n",
    "            \n",
    "            #options = ['/workspace/temp/temp/snap6/snap6/bin/gpt',\n",
    "            #   '-x',\n",
    "            #   '-c',\n",
    "            #   '2048M',\n",
    "            #   path]\n",
    "\n",
    "            p = subprocess.Popen(options,\n",
    "                stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "            print p.pid\n",
    "            res, err = p.communicate()\n",
    "            print res, err\n",
    "            if p.returncode != 0:\n",
    "                raise Exception('An error occurred during the execution of gpt (see log)')\n",
    "            \n",
    "        except Exception as e:\n",
    "            with open('stdout.txt', 'wb') as file:\n",
    "                file.write(res)\n",
    "                file.close()\n",
    "            with open('stderr.txt', 'wb') as file:\n",
    "                file.write(err)\n",
    "                file.close()\n",
    "            \n",
    "            raise\n",
    "        finally:\n",
    "            os.remove(path)\n",
    "        \n",
    "def get_snap_parameters(operator):\n",
    "    \n",
    "    op_spi = GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpi(operator)\n",
    "\n",
    "    op_params = op_spi.getOperatorDescriptor().getParameterDescriptors()\n",
    "\n",
    "    return op_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Get S-1 metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciop = cioppy.Cioppy()\n",
    "\n",
    "search = ciop.search(end_point=input_references[0],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP') \n",
    "\n",
    "search2 = ciop.search(end_point=input_references[1],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP')\n",
    "\n",
    "# slave image - always the post-event\n",
    "input_identifiers_slv_mst = []\n",
    "\n",
    "if (search[0]['startdate'] < search2[0]['startdate']):\n",
    "    \n",
    "    start_date = search[0]['startdate']\n",
    "    \n",
    "    input_identifiers_slv_mst.append(input_identifiers[1])\n",
    "    input_identifiers_slv_mst.append(input_identifiers[0])\n",
    "    \n",
    "    mst_date_str = parser.parse(search[0]['startdate']).strftime('%d%b%Y')\n",
    "    slv_date_str = parser.parse(search2[0]['startdate']).strftime('%d%b%Y')\n",
    "      \n",
    "else:\n",
    "    \n",
    "    start_date = search2[0]['startdate']\n",
    "    \n",
    "    input_identifiers_slv_mst.append(input_identifiers[0])\n",
    "    input_identifiers_slv_mst.append(input_identifiers[1])\n",
    "    \n",
    "    slv_date_str = parser.parse(search[0]['startdate']).strftime('%d%b%Y')\n",
    "    mst_date_str = parser.parse(search2[0]['startdate']).strftime('%d%b%Y')\n",
    "\n",
    "if (search[0]['enddate'] > search2[0]['enddate']):\n",
    "    end_date = search[0]['enddate']\n",
    "else:\n",
    "    end_date = search2[0]['enddate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Slave image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1. Read s-1 product (slave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "index = 0\n",
    "identifier = input_identifiers_slv_mst[index]\n",
    "    \n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        parameters[param.getName()] = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')    \n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "        \n",
    "node_id = 'Read(%s)' % index\n",
    "    \n",
    "read_node = node_id\n",
    "    \n",
    "print(parameters)\n",
    "    \n",
    "mygraph.add_node(node_id, 'Read', parameters, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "source_node = read_node\n",
    "    \n",
    "node_id = 'Apply-Orbit-File(%s)' % index\n",
    "    \n",
    "orbit_node = node_id\n",
    "    \n",
    "mygraph.add_node(node_id, 'Apply-Orbit-File', parameters, source_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. TOPSAR split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Split'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_split_nodes = []\n",
    "\n",
    "index_node = 0\n",
    "source_node = orbit_node\n",
    "\n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "    \n",
    "    parameters['subswath'] =  subswath\n",
    "    parameters['selectedPolarisations'] = 'VV'\n",
    "\n",
    "    node_id = 'TOPSAR-Split(%s)' % str(index)\n",
    "    \n",
    "    \n",
    "    slave_split_nodes.append(node_id)\n",
    "\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4. ThermalNoiseRemoval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'ThermalNoiseRemoval'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_tr_nodes = []\n",
    "\n",
    "for index, slave_split_node in enumerate(slave_split_nodes):\n",
    "    \n",
    "    node_id = 'ThermalNoiseRemoval(%s)' % index\n",
    "    \n",
    "    source_node = slave_split_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_tr_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Calibration'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'outputSigmaBand':\n",
    "        parameters[param.getName()] = 'false'\n",
    "    elif param.getName() == 'outputBetaBand':\n",
    "        parameters[param.getName()] = 'true'      \n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_cal_nodes = []\n",
    "\n",
    "for index, slave_tr_node in enumerate(slave_tr_nodes):\n",
    "    \n",
    "    node_id = 'Calibration(%s)' % index\n",
    "    \n",
    "    source_node = slave_tr_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_cal_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6. TOPSAR-Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Deburst'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_deb_nodes = []\n",
    "\n",
    "for index, slave_cal_node in enumerate(slave_cal_nodes):\n",
    "    \n",
    "    node_id = 'TOPSAR-Deburst(%s)' % index\n",
    "    \n",
    "    source_node = slave_cal_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_deb_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7. TOPSAR-Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Merge'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_merge_nodes = []\n",
    "\n",
    "node_id = 'TOPSAR-Merge(%s)' % str(0)\n",
    "source_nodes = []\n",
    "\n",
    "for index, slave_deb_node in enumerate(slave_deb_nodes):\n",
    "    \n",
    "    source_nodes.append(slave_deb_node)\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "slave_merge_node = node_id\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.8. Multilook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Multilook'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'nRgLooks':\n",
    "        parameters[param.getName()] = '4'\n",
    "    elif param.getName() == 'outputIntensity':\n",
    "        parameters[param.getName()] = 'true'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "    \n",
    "node_id = 'Multilook(%s)' % index\n",
    "    \n",
    "source_node = slave_merge_node\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "slave_ml_node = node_id\n",
    "    \n",
    "print(node_id)\n",
    "    \n",
    "print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.9. Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    "\n",
    "output_name_slave = os.path.join(temp_folder, 'temp_slave')\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        \n",
    "        param_value = output_name_slave\n",
    "             \n",
    "    elif param.getName() == 'formatName':\n",
    "                \n",
    "        param_value = 'BEAM-DIMAP'\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        param_value = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    print (param.getName(), param_value)\n",
    "    \n",
    "    parameters[param.getName()] = param_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(operator, \n",
    "             operator, \n",
    "             parameters,\n",
    "             slave_ml_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.10. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Master pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1. Read s-1 product (master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "index = 1\n",
    "identifier = input_identifiers_slv_mst[index]\n",
    "    \n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        parameters[param.getName()] = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')    \n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "        \n",
    "node_id = 'Read(%s)' % index\n",
    "    \n",
    "read_node = node_id\n",
    "    \n",
    "print(parameters)\n",
    "    \n",
    "mygraph.add_node(node_id, 'Read', parameters, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "source_node = read_node\n",
    "    \n",
    "node_id = 'Apply-Orbit-File(%s)' % index\n",
    "    \n",
    "orbit_node = node_id\n",
    "    \n",
    "mygraph.add_node(node_id, 'Apply-Orbit-File', parameters, source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3. TOPSAR split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Split'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_split_nodes = []\n",
    "\n",
    "index_node = 1\n",
    "source_node = orbit_node\n",
    "\n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "    \n",
    "    parameters['subswath'] =  subswath\n",
    "    parameters['selectedPolarisations'] = 'VV'\n",
    "\n",
    "    node_id = 'TOPSAR-Split(%s)' % str(index)\n",
    "    \n",
    "    \n",
    "    slave_split_nodes.append(node_id)\n",
    "\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4. ThermalNoiseRemoval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'ThermalNoiseRemoval'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_tr_nodes = []\n",
    "\n",
    "for index, slave_split_node in enumerate(slave_split_nodes):\n",
    "    \n",
    "    node_id = 'ThermalNoiseRemoval(%s)' % index\n",
    "    \n",
    "    source_node = slave_split_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_tr_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Calibration'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'outputSigmaBand':\n",
    "        parameters[param.getName()] = 'false'\n",
    "    elif param.getName() == 'outputBetaBand':\n",
    "        parameters[param.getName()] = 'true'      \n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_cal_nodes = []\n",
    "\n",
    "for index, slave_tr_node in enumerate(slave_tr_nodes):\n",
    "    \n",
    "    node_id = 'Calibration(%s)' % index\n",
    "    \n",
    "    source_node = slave_tr_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_cal_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6. TOPSAR-Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Deburst'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_deb_nodes = []\n",
    "\n",
    "for index, slave_cal_node in enumerate(slave_cal_nodes):\n",
    "    \n",
    "    node_id = 'TOPSAR-Deburst(%s)' % index\n",
    "    \n",
    "    source_node = slave_cal_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_deb_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.7. TOPSAR-Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Merge'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_merge_nodes = []\n",
    "\n",
    "node_id = 'TOPSAR-Merge(%s)' % str(1)\n",
    "source_nodes = []\n",
    "\n",
    "for index, slave_deb_node in enumerate(slave_deb_nodes):\n",
    "    \n",
    "    source_nodes.append(slave_deb_node)\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "slave_merge_node = node_id\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.8. Multilook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Multilook'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'nRgLooks':\n",
    "        parameters[param.getName()] = '4'\n",
    "    elif param.getName() == 'outputIntensity':\n",
    "        parameters[param.getName()] = 'true'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "    \n",
    "node_id = 'Multilook(%s)' % index\n",
    "    \n",
    "source_node = slave_merge_node\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "slave_ml_node = node_id\n",
    "    \n",
    "print(node_id)\n",
    "    \n",
    "print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.9. Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    "\n",
    "output_name_master = os.path.join(temp_folder, 'temp_master')\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        \n",
    "        param_value = output_name_master\n",
    "             \n",
    "    elif param.getName() == 'formatName':\n",
    "                \n",
    "        param_value = 'BEAM-DIMAP'\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        param_value = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    print (param.getName(), param_value)\n",
    "    \n",
    "    parameters[param.getName()] = param_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(operator, \n",
    "             operator, \n",
    "             parameters,\n",
    "             slave_ml_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.10. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Read slave and master products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_products = [output_name_master, output_name_slave]\n",
    "\n",
    "operator = 'Read'\n",
    "\n",
    "read_nodes = []\n",
    "\n",
    "for index, identifier in enumerate(input_products):\n",
    "    \n",
    "    parameters = dict()\n",
    "\n",
    "    for param in get_snap_parameters(operator):\n",
    "    \n",
    "        if param.getName() == 'file':\n",
    "            parameters[param.getName()] = os.path.join(identifier + '.dim')    \n",
    "        else:\n",
    "            parameters[param.getName()] = param.getDefaultValue()\n",
    "    node_id = 'Read(%s)' % index\n",
    "    \n",
    "    read_nodes.append(node_id)\n",
    "    \n",
    "    print(parameters)\n",
    "    \n",
    "    mygraph.add_node(node_id, 'Read', parameters, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. DEM-Assisted-Coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'resamplingType':\n",
    "        parameters[param.getName()] = 'NEAREST_NEIGHBOUR'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_nodes = []\n",
    "\n",
    "node_id = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "source_nodes = read_nodes\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "cor_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3. Speckle-Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Speckle-Filter'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'filter':\n",
    "        parameters[param.getName()] = 'Frost'\n",
    "    elif param.getName() == 'filterSizeX':\n",
    "        parameters[param.getName()] = '5'\n",
    "    elif param.getName() == 'filterSizeY':\n",
    "        parameters[param.getName()] = '5'\n",
    "    elif param.getName() == 'dampingFactor':\n",
    "        parameters[param.getName()] = '2'\n",
    "    elif param.getName() == 'estimateENL':\n",
    "        parameters[param.getName()] = 'true'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_nodes = []\n",
    "\n",
    "node_id = 'Speckle-Filter'\n",
    "\n",
    "source_nodes = cor_nodes[0]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "fil_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4. BandMaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'BandMaths'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'targetBandDescriptors':\n",
    "        pass\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "\n",
    "expression_str = 'log( Beta0_VV_slv1_{0} / Beta0_VV_mst_{1})'.format(slv_date_str, mst_date_str)\n",
    "        \n",
    "targetbandsdic = {'targetBand': {'name': 'dif', 'type': 'float32', 'expression': expression_str, 'description': None, 'unit': None, 'noDataValue': '-9999'}}\n",
    "\n",
    "\n",
    "parameters['targetBands'] = targetbandsdic\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_nodes = []\n",
    "\n",
    "node_id = 'BandMaths'\n",
    "\n",
    "source_nodes = fil_nodes[0]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "math_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5. Ellipsoid-Correction-RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "operator = 'Ellipsoid-Correction-RD'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'pixelSpacingInMeter':\n",
    "        parameters[param.getName()] = '14.71'\n",
    "    elif param.getName() == 'pixelSpacingInDegree':\n",
    "        parameters[param.getName()] = '1.321421782939816E-4'\n",
    "    #elif param.getName() == 'mapProjection':\n",
    "    #    parameters[param.getName()] = \"GEOGCS[&quot;WGS84(DD)&quot;, &#xd;DATUM[&quot;WGS84&quot;, &#xd;SPHEROID[&quot;WGS84&quot;, 6378137.0, 298.257223563]], &#xd;PRIMEM[&quot;Greenwich&quot;, 0.0], &#xd;UNIT[&quot;degree&quot;, 0.017453292519943295], &#xd;AXIS[&quot;Geodetic longitude&quot;, EAST], &#xd;AXIS[&quot;Geodetic latitude&quot;, NORTH]]\"\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ellip_nodes = []\n",
    "\n",
    "node_id = 'Ellipsoid-Correction-RD'\n",
    "\n",
    "source_nodes = math_nodes[0]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "ellip_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Terrain-Correction'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellip_nodes = []\n",
    "\n",
    "node_id = 'Terrain-Correction'\n",
    "\n",
    "source_nodes = math_nodes[0]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "ellip_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6. Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'S1_B0CH_%s_%s_%s' % (\"%03d\"%int(search[0]['wrsLongitudeGrid']), \n",
    "                                    parser.parse(start_date).strftime('%Y%m%d_%H%M%S'),\n",
    "                                    parser.parse(end_date).strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    " \n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        \n",
    "        param_value = output_name\n",
    "             \n",
    "    elif param.getName() == 'formatName':\n",
    "                \n",
    "        param_value = 'BEAM-DIMAP'\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        param_value = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    print param.getName(), param_value\n",
    "    \n",
    "    parameters[param.getName()] = param_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(operator, \n",
    "             operator, \n",
    "             parameters,\n",
    "             ellip_nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.7. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write result in GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ProductIO.getProductReader(\"BEAM-DIMAP\")\n",
    "\n",
    "b0ch = reader.readProductNodes(output_name + '.dim', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tif_name = os.path.join(temp_folder, output_name + '.tif')\n",
    "\n",
    "ProductIO.writeProduct(b0ch, \n",
    "                       temp_tif_name,\n",
    "                       'GeoTIFF-BigTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set no data value in the geotiff file \n",
    "\n",
    "dataset = gdal.Open(temp_tif_name)\n",
    "\n",
    "gdal.Translate(output_name + '.tif', dataset, noData=-9999)\n",
    "\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eop_metadata(metadata):\n",
    "\n",
    "    opt = 'http://www.opengis.net/opt/2.1'\n",
    "    om  = 'http://www.opengis.net/om/2.0'\n",
    "    gml = 'http://www.opengis.net/gml/3.2'\n",
    "    eop = 'http://www.opengis.net/eop/2.1'\n",
    "    sar = 'http://www.opengis.net/sar/2.1'\n",
    "    \n",
    "    root = etree.Element('{%s}EarthObservation' % sar)\n",
    "\n",
    "    phenomenon_time = etree.SubElement(root, '{%s}phenomenonTime' % om)\n",
    "\n",
    "    time_period = etree.SubElement(phenomenon_time, '{%s}TimePeriod' % gml)\n",
    "\n",
    "    begin_position = etree.SubElement(time_period, '{%s}beginPosition'  % gml)\n",
    "\n",
    "    end_position = etree.SubElement(time_period, '{%s}endPosition'  % gml)\n",
    "\n",
    "    procedure = etree.SubElement(root, '{%s}procedure' % om)\n",
    "\n",
    "    earth_observation_equipment = etree.SubElement(procedure, '{%s}EarthObservationEquipment' % eop)\n",
    "\n",
    "    acquisition_parameters = etree.SubElement(earth_observation_equipment, '{%s}acquisitionParameters' % eop)\n",
    "\n",
    "    acquisition = etree.SubElement(acquisition_parameters, '{%s}Acquisition' % sar)\n",
    "\n",
    "    orbit_number = etree.SubElement(acquisition, '{%s}orbitNumber' % eop)\n",
    "\n",
    "    wrs_longitude_grid = etree.SubElement(acquisition, '{%s}wrsLongitudeGrid' % eop)\n",
    "\n",
    "    polarisation_channels = etree.SubElement(acquisition, '{%s}polarisationChannels' % eop)\n",
    "    \n",
    "    feature_of_interest = etree.SubElement(root, '{%s}featureOfInterest' % om)\n",
    "    footprint = etree.SubElement(feature_of_interest, '{%s}Footprint' % eop)\n",
    "    multi_extentOf = etree.SubElement(footprint, '{%s}multiExtentOf' % eop)\n",
    "    multi_surface = etree.SubElement(multi_extentOf, '{%s}MultiSurface' % gml)\n",
    "    surface_members = etree.SubElement(multi_surface, '{%s}surfaceMembers' % gml)\n",
    "    polygon = etree.SubElement(surface_members, '{%s}Polygon' % gml)    \n",
    "    exterior = etree.SubElement(polygon, '{%s}exterior' % gml)  \n",
    "    linear_ring = etree.SubElement(exterior, '{%s}LinearRing' % gml) \n",
    "    poslist = etree.SubElement(linear_ring, '{%s}posList' % gml) \n",
    "\n",
    "\n",
    "    result = etree.SubElement(root, '{%s}result' % om)\n",
    "    earth_observation_result = etree.SubElement(result, '{%s}EarthObservationResult' % opt)\n",
    "    cloud_cover_percentage = etree.SubElement(earth_observation_result, '{%s}cloudCoverPercentage' % opt)\n",
    "    \n",
    "    metadata_property = etree.SubElement(root, '{%s}metaDataProperty' % eop)\n",
    "    earth_observation_metadata = etree.SubElement(metadata_property, '{%s}EarthObservationMetaData' % eop)\n",
    "    identifier = etree.SubElement(earth_observation_metadata, '{%s}identifier' % eop)\n",
    "    \n",
    "    begin_position.text = metadata['startdate']\n",
    "    end_position.text = metadata['enddate']\n",
    "    #orbit_number.text = metadata['orbitNumber']\n",
    "    wrs_longitude_grid.text = metadata['wrsLongitudeGrid']\n",
    "    \n",
    "    coords = np.asarray([t[::-1] for t in list(loads(metadata['wkt']).exterior.coords)]).tolist()\n",
    " \n",
    "    pos_list = ''\n",
    "    for elem in coords:\n",
    "        pos_list += ' '.join(str(e) for e in elem) + ' '   \n",
    "\n",
    "    poslist.attrib['count'] = str(len(coords))\n",
    "    poslist.text = pos_list\n",
    "    \n",
    "    \n",
    "    identifier.text = metadata['identifier'] \n",
    "\n",
    "    return etree.tostring(root, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(output_name + '.tif')\n",
    "ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "\n",
    "max_x = ulx + (src.RasterXSize * xres)\n",
    "min_y = uly + (src.RasterYSize * yres)\n",
    "min_x = ulx \n",
    "max_y = uly\n",
    "\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromWkt(src.GetProjection())\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(4326)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "result_wkt = box(transform.TransformPoint(min_x, min_y)[0],\n",
    "        transform.TransformPoint(min_x, min_y)[1],\n",
    "        transform.TransformPoint(max_x, max_y)[0],\n",
    "        transform.TransformPoint(max_x, max_y)[1]).wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search[0]['identifier'] = output_name\n",
    "search[0]['wkt'] = result_wkt\n",
    "\n",
    "search[0]['startdate'] = start_date\n",
    "search[0]['enddate'] = end_date\n",
    "\n",
    "eop_xml = output_name + '.xml'\n",
    "with open(eop_xml, 'wb') as file:\n",
    "    file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    file.write(eop_metadata(search[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for properties_file in ['result', 'stage-in']:\n",
    "\n",
    "    if properties_file == 'result':\n",
    "        title = 'Reproducibility notebook used for generating %s' % output_name\n",
    "    else: \n",
    "        title = 'Reproducibility stage-in notebook for Sentinel-1 data for generating %s' % output_name\n",
    "        \n",
    "    with open(properties_file + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (start_date, end_date))\n",
    "        file.write('geometry=%s' % (search[0]['wkt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_folder)\n",
    "\n",
    "shutil.rmtree(output_name + '.data')\n",
    "os.remove(output_name + '.dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"License\"> License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
