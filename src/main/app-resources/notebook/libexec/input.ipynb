{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ETHZ-03-02-01 Map of b0 changes - Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data processor developer, I want to implement, and package an algorithm processing a pair of S1 SAR SLC datasets using the SNAP toolbox notebook archetype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quick link\n",
    "\n",
    "* [Objective](#objective)\n",
    "* [Test Site](#test-site)\n",
    "* [Context](#context)\n",
    "* [Applicability](#applicability)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [Strengths and Limitations](#strengths-limitations) \n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"objective\">Objective \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"data\">Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "SENTINEL data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. Radar data will be delivered within an hour of reception for Near Real-Time (NRT) emergency response, within three hours for NRT priority areas and within 24 hours for systematically archived data.\n",
    "\n",
    "All data products are distributed in the SENTINEL Standard Archive Format for Europe (SAFE) format.\n",
    "\n",
    "Data products are available in single polarisation (VV or HH) for Wave mode and dual polarisation (VV+VH or HH+HV) and single polarisation (HH or VV) for SM, IW and EW modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ETHZ-03-02-01 Map of b0 changes'),\n",
    "                ('abstract', 'This application takes a pair of Sentinel-1 products and generates a map of b0 changes'),\n",
    "                ('id', 'ewf-ethz-03-02-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output file format:\n",
    "\n",
    "* BEAM-DIMAP\n",
    "* GeoTIFF-BigTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = dict([('id', 'format'),\n",
    "               ('value', 'GeoTIFF-BigTIFF'),\n",
    "               ('title', 'Output file format'),\n",
    "               ('abstract', 'Output file format: BEAM-DIMAP or GeoTIFF-BigTIFF')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition\n",
    "    \n",
    "The variable values in this section are only relevant for the basic test case. In an actual processing context, the values are replaced by those of the parameters for the process execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of master and slave products' identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_identifiers = ('S1A_IW_SLC__1SDV_20161030T163141_20161030T163208_013722_01603F_4094', 'S1A_IW_SLC__1SDV_20161018T163141_20161018T163208_013547_015AEB_5994')\n",
    "\n",
    "input_identifiers = ('S1A_IW_SLC__1SDV_20161107T170553_20161107T170620_013839_0163F7_A66D', 'S1A_IW_SLC__1SDV_20161026T170553_20161026T170620_013664_015E7F_BD83')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack of catalogue references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input_references = ('https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161030T163141_20161030T163208_013722_01603F_4094', 'https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161018T163141_20161018T163208_013547_015AEB_5994')\n",
    "\n",
    "input_references = ('https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161107T170553_20161107T170620_013839_0163F7_A66D','https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20161026T170553_20161026T170620_013664_015E7F_BD83')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/Better_3rd_phase/Applications/ETHZ-03-02-01/temp/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "\n",
    "import dateutil.parser as parser\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import gdal\n",
    "import osr\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import box\n",
    "\n",
    "import lxml.etree as etree\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as etree\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "import psutil\n",
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "import os\n",
    "\n",
    "class GraphProcessor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.root = etree.Element('graph')\n",
    "    \n",
    "        version = etree.SubElement(self.root, 'version')\n",
    "        version.text = '1.0'\n",
    "        self.pid = None\n",
    "        self.p = None\n",
    "   \n",
    "    def view_graph(self):\n",
    "        \n",
    "        print etree.tostring(self.root , pretty_print=True)\n",
    "        \n",
    "    def add_node(self, node_id, operator, parameters, source):\n",
    "    \n",
    "        xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "\n",
    "        if len(self.root.xpath(xpath_expr)) != 0:\n",
    "\n",
    "            node_elem = self.root.xpath(xpath_expr)[0]\n",
    "            operator_elem = self.root.xpath(xpath_expr + '/operator')[0]\n",
    "            sources_elem = self.root.xpath(xpath_expr + '/sources')[0]\n",
    "            parameters_elem = self.root.xpath(xpath_expr + '/parameters')\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "                p_elem = self.root.xpath(xpath_expr + '/parameters/%s' % key)[0]\n",
    "                p_elem.text = value\n",
    "        else:\n",
    "\n",
    "            node_elem = etree.SubElement(self.root, 'node')\n",
    "            operator_elem = etree.SubElement(node_elem, 'operator')\n",
    "            sources_elem = etree.SubElement(node_elem, 'sources')\n",
    "\n",
    "            if isinstance(source, list):\n",
    "\n",
    "                for index, s in enumerate(source):\n",
    "                    if index == 0:  \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "\n",
    "                    else: \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct.%s' % str(index))\n",
    "\n",
    "                    source_product_elem.attrib['refid'] = s\n",
    "\n",
    "            elif source != '':\n",
    "                source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "                source_product_elem.attrib['refid'] = source\n",
    "\n",
    "            parameters_elem = etree.SubElement(node_elem, 'parameters')\n",
    "            parameters_elem.attrib['class'] = 'com.bc.ceres.binding.dom.XppDomElement'\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "\n",
    "                # here I have to adapt the code\n",
    "                \n",
    "                if operator == 'BandMaths':\n",
    "                    \n",
    "                    if isinstance(value, dict):\n",
    "                        \n",
    "                        parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                        \n",
    "                        for key2, value2 in value.iteritems():\n",
    "                            parameter_elem2 = etree.SubElement(parameter_elem, key2)\n",
    "                            #parameter_elem.text = value\n",
    "                            if isinstance(value2, dict):\n",
    "                                for key3, value3 in value2.iteritems():\n",
    "                                    parameter_elem3 = etree.SubElement(parameter_elem2, key3)\n",
    "                                    parameter_elem3.text = value3\n",
    "                            pass\n",
    "                    \n",
    "                    else:\n",
    "                        parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                        parameter_elem.text = value\n",
    "                else:\n",
    "                    parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                    parameter_elem.text = value\n",
    "                    \n",
    "                    \n",
    "        \n",
    "        node_elem.attrib['id'] = node_id\n",
    "\n",
    "        operator_elem.text = operator \n",
    "\n",
    "    def save_graph(self, filename):\n",
    "        \n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "            file.write(etree.tostring(self.root, pretty_print=True))\n",
    "     \n",
    "    def plot_graph(self):\n",
    "        \n",
    "        for node_id in self.root.xpath('/graph/node/@id'):\n",
    "            \n",
    "\n",
    "            xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "            \n",
    "            if len(self.root.xpath(xpath_expr + '/sources/sourceProduct')) != 0:\n",
    "                print(self.root.xpath(xpath_expr + '/sources/sourceProduct'))[0].attrib['refid']\n",
    "                print node_id\n",
    "            else:\n",
    "                print node_id\n",
    "        return True\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        fd, path = tempfile.mkstemp()\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            self.save_graph(filename=path)\n",
    "            \n",
    "            #options = ['/opt/snap6/bin/gpt',\n",
    "            #   '-x',\n",
    "            #   '-c',\n",
    "            #   '2048M',\n",
    "            #   path]\n",
    "            \n",
    "            options = ['/workspace/temp/temp/snap6/snap6/bin/gpt',\n",
    "               '-x',\n",
    "               '-c',\n",
    "               '2048M',\n",
    "               path]\n",
    "\n",
    "            p = subprocess.Popen(options,\n",
    "                stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "            print p.pid\n",
    "            res, err = p.communicate()\n",
    "            print res, err\n",
    "            if p.returncode != 0:\n",
    "                raise Exception('An error occurred during the execution of gpt (see log)')\n",
    "            \n",
    "        except Exception as e:\n",
    "            with open('stdout.txt', 'wb') as file:\n",
    "                file.write(res)\n",
    "                file.close()\n",
    "            with open('stderr.txt', 'wb') as file:\n",
    "                file.write(err)\n",
    "                file.close()\n",
    "            \n",
    "            raise\n",
    "        finally:\n",
    "            os.remove(path)\n",
    "        \n",
    "def get_snap_parameters(operator):\n",
    "    \n",
    "    op_spi = GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpi(operator)\n",
    "\n",
    "    op_params = op_spi.getOperatorDescriptor().getParameterDescriptors()\n",
    "\n",
    "    return op_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Slave preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Read s-1 product (slave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "index = 0\n",
    "identifier = input_identifiers[index]\n",
    "    \n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        parameters[param.getName()] = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')    \n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "        \n",
    "node_id = 'Read(%s)' % index\n",
    "    \n",
    "read_node = node_id\n",
    "    \n",
    "print(parameters)\n",
    "    \n",
    "mygraph.add_node(node_id, 'Read', parameters, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "source_node = read_node\n",
    "    \n",
    "node_id = 'Apply-Orbit-File(%s)' % index\n",
    "    \n",
    "orbit_node = node_id\n",
    "    \n",
    "mygraph.add_node(node_id, 'Apply-Orbit-File', parameters, source_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. TOPSAR split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Split'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_split_nodes = []\n",
    "\n",
    "index_node = 0\n",
    "source_node = orbit_node\n",
    "\n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "    \n",
    "    parameters['subswath'] =  subswath\n",
    "    parameters['selectedPolarisations'] = 'VV'\n",
    "\n",
    "    node_id = 'TOPSAR-Split(%s)' % str(index)\n",
    "    \n",
    "    \n",
    "    slave_split_nodes.append(node_id)\n",
    "\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. ThermalNoiseRemoval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'ThermalNoiseRemoval'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_tr_nodes = []\n",
    "\n",
    "for index, slave_split_node in enumerate(slave_split_nodes):\n",
    "    \n",
    "    node_id = 'ThermalNoiseRemoval(%s)' % index\n",
    "    \n",
    "    source_node = slave_split_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_tr_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Calibration'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'outputSigmaBand':\n",
    "        parameters[param.getName()] = 'false'\n",
    "    elif param.getName() == 'outputBetaBand':\n",
    "        parameters[param.getName()] = 'true'      \n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_cal_nodes = []\n",
    "\n",
    "for index, slave_tr_node in enumerate(slave_tr_nodes):\n",
    "    \n",
    "    node_id = 'Calibration(%s)' % index\n",
    "    \n",
    "    source_node = slave_tr_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_cal_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. TOPSAR-Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Deburst'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_deb_nodes = []\n",
    "\n",
    "for index, slave_cal_node in enumerate(slave_cal_nodes):\n",
    "    \n",
    "    node_id = 'TOPSAR-Deburst(%s)' % index\n",
    "    \n",
    "    source_node = slave_cal_node\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "    slave_deb_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7. TOPSAR-Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Merge'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_merge_nodes = []\n",
    "\n",
    "node_id = 'TOPSAR-Merge(%s)' % str(0)\n",
    "source_nodes = []\n",
    "\n",
    "for index, slave_deb_node in enumerate(slave_deb_nodes):\n",
    "    \n",
    "    source_nodes.append(slave_deb_node)\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "slave_merge_node = node_id\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8. Multilook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Multilook'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'nRgLooks':\n",
    "        parameters[param.getName()] = '4'\n",
    "    elif param.getName() == 'outputIntensity':\n",
    "        parameters[param.getName()] = 'true'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "    \n",
    "node_id = 'Multilook(%s)' % index\n",
    "    \n",
    "source_node = slave_merge_node\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "    \n",
    "slave_ml_node = node_id\n",
    "    \n",
    "print(node_id)\n",
    "    \n",
    "print(source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9. Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    "\n",
    "output_name = 'temp_slave'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        \n",
    "        param_value = output_name\n",
    "             \n",
    "    elif param.getName() == 'formatName':\n",
    "                \n",
    "        param_value = 'BEAM-DIMAP'\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        param_value = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    print (param.getName(), param_value)\n",
    "    \n",
    "    parameters[param.getName()] = param_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(operator, \n",
    "             operator, \n",
    "             parameters,\n",
    "             slave_ml_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "read_nodes = []\n",
    "\n",
    "for index, identifier in enumerate(input_identifiers):\n",
    "    \n",
    "    parameters = dict()\n",
    "\n",
    "    for param in get_snap_parameters(operator):\n",
    "    \n",
    "        if param.getName() == 'file':\n",
    "            parameters[param.getName()] = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')    \n",
    "        else:\n",
    "            parameters[param.getName()] = param.getDefaultValue()\n",
    "    node_id = 'Read(%s)' % index\n",
    "    \n",
    "    read_nodes.append(node_id)\n",
    "    \n",
    "    print(parameters)\n",
    "    \n",
    "    mygraph.add_node(node_id, 'Read', parameters, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_nodes = []\n",
    "\n",
    "for index, source_node in enumerate(read_nodes):\n",
    "    \n",
    "    node_id = 'Apply-Orbit-File(%s)' % index\n",
    "    \n",
    "    orbit_nodes.append(node_id)\n",
    "    \n",
    "    mygraph.add_node(node_id, 'Apply-Orbit-File', parameters, source_node)\n",
    "    \n",
    "print('-----')\n",
    "print(mygraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPSAR split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Split'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_split_nodes = []\n",
    "master_split_nodes = []\n",
    "\n",
    "for index_node, source_node in enumerate(orbit_nodes):\n",
    "    \n",
    "    for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "    \n",
    "        parameters['subswath'] =  subswath\n",
    "        parameters['selectedPolarisations'] = 'VV'\n",
    "\n",
    "        node_id = 'TOPSAR-Split(%s)' % str(index_node * 3 + index)\n",
    "    \n",
    "        if index_node == 0:\n",
    "            slave_split_nodes.append(node_id)\n",
    "        else:\n",
    "            master_split_nodes.append(node_id)\n",
    "    \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ThermalNoiseRemoval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'ThermalNoiseRemoval'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_tr_nodes = []\n",
    "master_tr_nodes = []\n",
    "\n",
    "for index, slave_split_node in enumerate(slave_split_nodes):\n",
    "    \n",
    "    node_id = 'ThermalNoiseRemoval(%s)' % index\n",
    "    \n",
    "    source_nodes = slave_split_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    slave_tr_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)\n",
    "    \n",
    "\n",
    "\n",
    "for index, master_split_node in enumerate(master_split_nodes):\n",
    "    \n",
    "    node_id = 'ThermalNoiseRemoval(%s)' % str(index + 3)\n",
    "    \n",
    "    source_nodes = master_split_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    master_tr_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Calibration'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'outputSigmaBand':\n",
    "        parameters[param.getName()] = 'false'\n",
    "    elif param.getName() == 'outputBetaBand':\n",
    "        parameters[param.getName()] = 'true'      \n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_cal_nodes = []\n",
    "master_cal_nodes = []\n",
    "\n",
    "for index, slave_tr_node in enumerate(slave_tr_nodes):\n",
    "    \n",
    "    node_id = 'Calibration(%s)' % index\n",
    "    \n",
    "    source_nodes = slave_tr_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    slave_cal_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)\n",
    "    \n",
    "\n",
    "\n",
    "for index, master_tr_node in enumerate(master_tr_nodes):\n",
    "    \n",
    "    node_id = 'Calibration(%s)' % str(index + 3)\n",
    "    \n",
    "    source_nodes = master_tr_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    master_cal_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPSAR-Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Deburst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_deb_nodes = []\n",
    "master_deb_nodes = []\n",
    "\n",
    "for index, slave_cal_node in enumerate(slave_cal_nodes):\n",
    "    \n",
    "    node_id = 'TOPSAR-Deburst(%s)' % index\n",
    "    \n",
    "    source_nodes = slave_cal_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    slave_deb_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)\n",
    "    \n",
    "\n",
    "\n",
    "for index, master_cal_node in enumerate(master_cal_nodes):\n",
    "    \n",
    "    node_id = 'TOPSAR-Deburst(%s)' % str(index + 3)\n",
    "    \n",
    "    source_nodes = master_cal_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    master_deb_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPSAR-Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Merge'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_merge_nodes = []\n",
    "master_merge_nodes = []\n",
    "\n",
    "\n",
    "node_id = 'TOPSAR-Merge(%s)' % str(0)\n",
    "source_nodes = []\n",
    "for index, slave_deb_node in enumerate(slave_deb_nodes):\n",
    "    \n",
    "    source_nodes.append(slave_deb_nodes[index])\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "slave_merge_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)\n",
    "    \n",
    "\n",
    "node_id = 'TOPSAR-Merge(%s)' % str(1)\n",
    "source_nodes = []\n",
    "for index, master_deb_node in enumerate(master_deb_nodes):\n",
    "    \n",
    "    source_nodes.append(master_deb_nodes[index])\n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "master_merge_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Multilook'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'nRgLooks':\n",
    "        parameters[param.getName()] = '4'\n",
    "    elif param.getName() == 'outputIntensity':\n",
    "        parameters[param.getName()] = 'true'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "slave_ml_nodes = []\n",
    "master_ml_nodes = []\n",
    "\n",
    "for index, slave_merge_node in enumerate(slave_merge_nodes):\n",
    "    \n",
    "    node_id = 'Multilook(%s)' % index\n",
    "    \n",
    "    source_nodes = slave_merge_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    slave_ml_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)\n",
    "    \n",
    "\n",
    "\n",
    "for index, master_merge_node in enumerate(master_merge_nodes):\n",
    "    \n",
    "    node_id = 'Multilook(%s)' % str(index + 1)\n",
    "    \n",
    "    source_nodes = master_merge_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "    \n",
    "    master_ml_nodes.append(node_id)\n",
    "    \n",
    "    print(node_id)\n",
    "    \n",
    "    print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEM-Assisted-Coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: look at resamplingType\n",
    "operator = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'resamplingType':\n",
    "        parameters[param.getName()] = 'NEAREST_NEIGHBOUR'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_nodes = []\n",
    "\n",
    "node_id = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "source_nodes = [slave_ml_nodes[0], master_ml_nodes[0]]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "cor_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle-Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Speckle-Filter'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'filter':\n",
    "        parameters[param.getName()] = 'Frost'\n",
    "    elif param.getName() == 'filterSizeX':\n",
    "        parameters[param.getName()] = '5'\n",
    "    elif param.getName() == 'filterSizeY':\n",
    "        parameters[param.getName()] = '5'\n",
    "    elif param.getName() == 'dampingFactor':\n",
    "        parameters[param.getName()] = '2'\n",
    "    elif param.getName() == 'estimateENL':\n",
    "        parameters[param.getName()] = 'true'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_nodes = []\n",
    "\n",
    "node_id = 'Speckle-Filter'\n",
    "\n",
    "source_nodes = cor_nodes[0]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "fil_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BandMaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'BandMaths'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'targetBandDescriptors':\n",
    "        pass\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n",
    "    \n",
    "targetbandsdic = {'targetBand': {'name': 'dif', 'type': 'float32', 'expression': 'log(Beta0_VV_mst_07Nov2016 / Beta0_VV_slv1_26Oct2016)', 'description': None, 'unit': None, 'noDataValue': '0.0'}}\n",
    "\n",
    "\n",
    "parameters['targetBands'] = targetbandsdic\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_nodes = []\n",
    "\n",
    "node_id = 'BandMaths'\n",
    "\n",
    "source_nodes = fil_nodes[0]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "math_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ellipsoid-Correction-RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Ellipsoid-Correction-RD'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'pixelSpacingInMeter':\n",
    "        parameters[param.getName()] = '14.71'\n",
    "    elif param.getName() == 'pixelSpacingInDegree':\n",
    "        parameters[param.getName()] = '1.321421782939816E-4'\n",
    "    #elif param.getName() == 'mapProjection':\n",
    "    #    parameters[param.getName()] = \"GEOGCS[&quot;WGS84(DD)&quot;, &#xd;DATUM[&quot;WGS84&quot;, &#xd;SPHEROID[&quot;WGS84&quot;, 6378137.0, 298.257223563]], &#xd;PRIMEM[&quot;Greenwich&quot;, 0.0], &#xd;UNIT[&quot;degree&quot;, 0.017453292519943295], &#xd;AXIS[&quot;Geodetic longitude&quot;, EAST], &#xd;AXIS[&quot;Geodetic latitude&quot;, NORTH]]\"\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellip_nodes = []\n",
    "\n",
    "node_id = 'Ellipsoid-Correction-RD'\n",
    "\n",
    "source_nodes = math_nodes[0]\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "ellip_nodes.append(node_id)\n",
    "\n",
    "print(node_id)\n",
    "    \n",
    "print(source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciop = cioppy.Cioppy()\n",
    "\n",
    "search = ciop.search(end_point=input_references[0],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP') \n",
    "\n",
    "search2 = ciop.search(end_point=input_references[1],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP')\n",
    "\n",
    "if (search[0]['startdate'] < search2[0]['startdate']):\n",
    "    start_date = search[0]['startdate']\n",
    "else:\n",
    "    start_date = search2[0]['startdate']\n",
    "\n",
    "if (search[0]['enddate'] > search2[0]['enddate']):\n",
    "    end_date = search[0]['enddate']\n",
    "else:\n",
    "    end_date = search2[0]['enddate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'S1_IFG_%s_%s_%s' % (\"%03d\"%int(search[0]['wrsLongitudeGrid']), \n",
    "                                    parser.parse(start_date).strftime('%Y%m%d_%H%M%S'),\n",
    "                                    parser.parse(end_date).strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    " \n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        \n",
    "        param_value = output_name\n",
    "             \n",
    "    elif param.getName() == 'formatName':\n",
    "                \n",
    "        param_value = 'BEAM-DIMAP'\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        param_value = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    print param.getName(), param_value\n",
    "    \n",
    "    parameters[param.getName()] = param_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(operator, \n",
    "             operator, \n",
    "             parameters,\n",
    "             ellip_nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ProductIO.getProductReader(\"BEAM-DIMAP\")\n",
    "\n",
    "ifg = reader.readProductNodes(output_name + '.dim', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = ifg.getBandNames()\n",
    "target_bands = list(band_names) \n",
    "target_bands.append(target_bands[0].replace('i_', 'phase_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "\n",
    "targetBands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', len(target_bands))\n",
    "\n",
    "for index, band in enumerate(target_bands):\n",
    "     \n",
    "    targetBand = BandDescriptor()\n",
    "    \n",
    "    if 'phase_' in band:\n",
    "       \n",
    "        targetBand.expression = 'atan2(%s, %s)' % (target_bands[1], target_bands[0])\n",
    "   \n",
    "    else:\n",
    "    \n",
    "        targetBand.expression = band\n",
    "\n",
    "    targetBand.name = band\n",
    "    targetBand.type = 'float32'\n",
    "    \n",
    "    targetBands[index]= targetBand\n",
    "        \n",
    "\n",
    "parameters = HashMap()\n",
    "parameters.put('targetBands', targetBands)\n",
    "\n",
    "result = GPF.createProduct('BandMaths', parameters, ifg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductIO.writeProduct(result, \n",
    "                       output_name + '.tif',\n",
    "                       'GeoTIFF-BigTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eop_metadata(metadata):\n",
    "\n",
    "    opt = 'http://www.opengis.net/opt/2.1'\n",
    "    om  = 'http://www.opengis.net/om/2.0'\n",
    "    gml = 'http://www.opengis.net/gml/3.2'\n",
    "    eop = 'http://www.opengis.net/eop/2.1'\n",
    "    sar = 'http://www.opengis.net/sar/2.1'\n",
    "    \n",
    "    root = etree.Element('{%s}EarthObservation' % sar)\n",
    "\n",
    "    phenomenon_time = etree.SubElement(root, '{%s}phenomenonTime' % om)\n",
    "\n",
    "    time_period = etree.SubElement(phenomenon_time, '{%s}TimePeriod' % gml)\n",
    "\n",
    "    begin_position = etree.SubElement(time_period, '{%s}beginPosition'  % gml)\n",
    "\n",
    "    end_position = etree.SubElement(time_period, '{%s}endPosition'  % gml)\n",
    "\n",
    "    procedure = etree.SubElement(root, '{%s}procedure' % om)\n",
    "\n",
    "    earth_observation_equipment = etree.SubElement(procedure, '{%s}EarthObservationEquipment' % eop)\n",
    "\n",
    "    acquisition_parameters = etree.SubElement(earth_observation_equipment, '{%s}acquisitionParameters' % eop)\n",
    "\n",
    "    acquisition = etree.SubElement(acquisition_parameters, '{%s}Acquisition' % sar)\n",
    "\n",
    "    orbit_number = etree.SubElement(acquisition, '{%s}orbitNumber' % eop)\n",
    "\n",
    "    wrs_longitude_grid = etree.SubElement(acquisition, '{%s}wrsLongitudeGrid' % eop)\n",
    "\n",
    "    polarisation_channels = etree.SubElement(acquisition, '{%s}polarisationChannels' % eop)\n",
    "    \n",
    "    feature_of_interest = etree.SubElement(root, '{%s}featureOfInterest' % om)\n",
    "    footprint = etree.SubElement(feature_of_interest, '{%s}Footprint' % eop)\n",
    "    multi_extentOf = etree.SubElement(footprint, '{%s}multiExtentOf' % eop)\n",
    "    multi_surface = etree.SubElement(multi_extentOf, '{%s}MultiSurface' % gml)\n",
    "    surface_members = etree.SubElement(multi_surface, '{%s}surfaceMembers' % gml)\n",
    "    polygon = etree.SubElement(surface_members, '{%s}Polygon' % gml)    \n",
    "    exterior = etree.SubElement(polygon, '{%s}exterior' % gml)  \n",
    "    linear_ring = etree.SubElement(exterior, '{%s}LinearRing' % gml) \n",
    "    poslist = etree.SubElement(linear_ring, '{%s}posList' % gml) \n",
    "\n",
    "\n",
    "    result = etree.SubElement(root, '{%s}result' % om)\n",
    "    earth_observation_result = etree.SubElement(result, '{%s}EarthObservationResult' % opt)\n",
    "    cloud_cover_percentage = etree.SubElement(earth_observation_result, '{%s}cloudCoverPercentage' % opt)\n",
    "    \n",
    "    metadata_property = etree.SubElement(root, '{%s}metaDataProperty' % eop)\n",
    "    earth_observation_metadata = etree.SubElement(metadata_property, '{%s}EarthObservationMetaData' % eop)\n",
    "    identifier = etree.SubElement(earth_observation_metadata, '{%s}identifier' % eop)\n",
    "    \n",
    "    begin_position.text = metadata['startdate']\n",
    "    end_position.text = metadata['enddate']\n",
    "    #orbit_number.text = metadata['orbitNumber']\n",
    "    wrs_longitude_grid.text = metadata['wrsLongitudeGrid']\n",
    "    \n",
    "    coords = np.asarray([t[::-1] for t in list(loads(metadata['wkt']).exterior.coords)]).tolist()\n",
    " \n",
    "    pos_list = ''\n",
    "    for elem in coords:\n",
    "        pos_list += ' '.join(str(e) for e in elem) + ' '   \n",
    "\n",
    "    poslist.attrib['count'] = str(len(coords))\n",
    "    poslist.text = pos_list\n",
    "    \n",
    "    \n",
    "    identifier.text = metadata['identifier'] \n",
    "\n",
    "    return etree.tostring(root, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(output_name + '.tif')\n",
    "ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "\n",
    "max_x = ulx + (src.RasterXSize * xres)\n",
    "min_y = uly + (src.RasterYSize * yres)\n",
    "min_x = ulx \n",
    "max_y = uly\n",
    "\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromWkt(src.GetProjection())\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(4326)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "result_wkt = box(transform.TransformPoint(min_x, min_y)[0],\n",
    "        transform.TransformPoint(min_x, min_y)[1],\n",
    "        transform.TransformPoint(max_x, max_y)[0],\n",
    "        transform.TransformPoint(max_x, max_y)[1]).wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search[0]['identifier'] = output_name\n",
    "search[0]['wkt'] = result_wkt\n",
    "\n",
    "search[0]['startdate'] = start_date\n",
    "search[0]['enddate'] = end_date\n",
    "\n",
    "eop_xml = output_name + '.xml'\n",
    "with open(eop_xml, 'wb') as file:\n",
    "    file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    file.write(eop_metadata(search[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for properties_file in ['result', 'stage-in']:\n",
    "\n",
    "    if properties_file == 'result':\n",
    "        title = 'Reproducibility notebook used for generating %s' % output_name\n",
    "    else: \n",
    "        title = 'Reproducibility stage-in notebook for Sentinel-1 data for generating %s' % output_name\n",
    "        \n",
    "    with open(properties_file + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (start_date, end_date))\n",
    "        file.write('geometry=%s' % (search[0]['wkt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(output_name + '.data')\n",
    "os.remove(output_name + '.dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
